{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d364676f-98c5-4b83-a588-73da6d028d62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b10e4c-a1fe-4bce-a91d-ad75bfb63333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from tensorboardX) (1.26.2)\n",
      "Requirement already satisfied: packaging in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from tensorboardX) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from tensorboardX) (4.25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b93212a-1900-409a-a84d-e520720b648c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (0.9.16)\n",
      "Requirement already satisfied: torch in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from timm) (2.2.0)\n",
      "Requirement already satisfied: torchvision in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from timm) (0.17.0)\n",
      "Requirement already satisfied: pyyaml in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface_hub in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from timm) (0.20.3)\n",
      "Requirement already satisfied: safetensors in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from timm) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.2.0)\n",
      "Requirement already satisfied: requests in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (23.1)\n",
      "Requirement already satisfied: sympy in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: numpy in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torchvision->timm) (1.26.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tomdadude/anaconda3/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac7b264-8b18-4239-af4a-e9b6b81a5122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import necessary library.\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "# from torchvision import tv_tensors\n",
    "# from torchvision.transforms.v2 import functional as F\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8922f57f-578c-4f5c-9402-c5a46371c819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./train/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c554529-d381-4cf7-b06d-07cf4a5b4026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b349a7-f4f7-4414-8355-1298b3834388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 240)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "np.array(Image.open('../dataset/train/images/'+ '1.jpg').convert('L')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3280b725-fe28-41f6-9c68-137986ac43ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image-name</th>\n",
       "      <th>label</th>\n",
       "      <th>label-name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>bonus-winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>characters-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>dots-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>bonus-summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>honors-east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>624.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>bamboo-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>625.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>dots-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>626.jpg</td>\n",
       "      <td>19</td>\n",
       "      <td>characters-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>627.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>bamboo-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>628.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>dots-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image-name  label    label-name\n",
       "0        1.jpg     38  bonus-winter\n",
       "1        2.jpg     26  characters-8\n",
       "2        3.jpg      9        dots-9\n",
       "3        4.jpg     36  bonus-summer\n",
       "4        5.jpg     28   honors-east\n",
       "..         ...    ...           ...\n",
       "624    624.jpg     11      bamboo-2\n",
       "625    625.jpg      2        dots-2\n",
       "626    626.jpg     19  characters-1\n",
       "627    627.jpg     10      bamboo-1\n",
       "628    628.jpg      1        dots-1\n",
       "\n",
       "[629 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4560ed08-c9c4-4c2f-8f58-abb3dd39ecd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# for i in range(42):\n",
    "#     os.makedirs('./label_all/'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc81fbba-423f-4182-a77c-97b77cfd21aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# for i in range(583, len(data)):\n",
    "#     source = '../dataset/train/images/'+ data['image-name'][i]\n",
    "#     target = './label_all/'+ str(data['label'][i])\n",
    "#     shutil.move(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b98de7a-cd90-4d9b-8c63-f231bb3905a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f750d6c4-db0e-4e5b-90b8-cd808f13c0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# image_list=glob.glob('./label_all/*/*.jpg')\n",
    "# # print(image_list)\n",
    "# file_dir='data2'\n",
    "# if os.path.exists(file_dir):\n",
    "#     print('true')\n",
    "#     #os.rmdir(file_dir)\n",
    "#     shutil.rmtree(file_dir)#删除再建立\n",
    "#     os.makedirs(file_dir)\n",
    "# else:\n",
    "#     os.makedirs(file_dir)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test = train_test_split(image_list, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# train_dir='train'\n",
    "# test_dir='test'\n",
    "\n",
    "# train_root=os.path.join(file_dir,train_dir)\n",
    "# test_root=os.path.join(file_dir,test_dir)\n",
    "# for file in X_train:\n",
    "#     file_class=file.replace(\"\\\\\",\"/\").split('/')[-2]\n",
    "#     file_name=file.replace(\"\\\\\",\"/\").split('/')[-1]\n",
    "#     file_class=os.path.join(train_root,file_class)\n",
    "#     if not os.path.isdir(file_class):\n",
    "#         os.makedirs(file_class)\n",
    "#     shutil.copy(file, file_class + '/' + file_name)\n",
    "\n",
    "    \n",
    "# for file in X_test:\n",
    "#     file_class=file.replace(\"\\\\\",\"/\").split('/')[-2]\n",
    "#     file_name=file.replace(\"\\\\\",\"/\").split('/')[-1]\n",
    "#     file_class=os.path.join(test_root,file_class)\n",
    "#     if not os.path.isdir(file_class):\n",
    "#         os.makedirs(file_class)\n",
    "#     shutil.copy(file, file_class + '/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0530c067-488b-4f9d-a1f1-c02ec8b49349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "import pdb\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.modu1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout2d()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(128*6*6, 42) #42 class\n",
    "        self.fc2 = nn.Linear(128*6*6, 1) #distermin 0,1\n",
    "        self.bn = nn.BatchNorm2d(128)\n",
    "    def forward(self, x, if_bn = True, feature = False, cuda = False):\n",
    "        x = self.modu1(x) # x.shape([1, 128, 6, 6])\n",
    "        if if_bn:\n",
    "            x = self.bn(x)\n",
    "        x = torch.reshape(x, (-1, 128*6*6)) # 4D to 2D\n",
    "        class_out = self.fc1(x)\n",
    "        real_fake_out = self.fc2(x)\n",
    "        # not activiate net\n",
    "        if feature:\n",
    "            return class_out, real_fake_out\n",
    "        else:\n",
    "            return class_out\n",
    "        \n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.genModel1 = nn.Sequential(\n",
    "            nn.Linear(100,  256 * 7 * 7 ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256 * 7 * 7),\n",
    "        )\n",
    "        self.genModel2 = nn.Sequential(\n",
    "            # [128, 28, 28]\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # [64, 14, 14] \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # [1, 28, 28]\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self,  batch_size, cuda = False):\n",
    "        x = Variable(torch.rand(batch_size, 100), requires_grad = False, volatile = not self.training)\n",
    "        x = self.genModel1(x)\n",
    "        x = torch.reshape(x, (-1, 256, 7, 7))\n",
    "        x = self.genModel2(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca12b342-9632-47cc-ae4b-272f44d10846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def MahjongLabel(class_num):\n",
    "    class_tot = [0] * 42\n",
    "    data = []\n",
    "    labels = []\n",
    "    positive_tot = 0\n",
    "    tot = 0\n",
    "    raw_dataset =  datasets.ImageFolder('./data2/train', \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((28, 28)),\n",
    "                       transforms.Grayscale(num_output_channels=1),\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "\n",
    "    \n",
    "    \n",
    "    perm = np.random.permutation(raw_dataset.__len__())\n",
    "    for i in range(raw_dataset.__len__()):\n",
    "        datum, label = raw_dataset.__getitem__(perm[i])\n",
    "        # label = label - 1\n",
    "        try:\n",
    "            if class_tot[label] < class_num:\n",
    "                data.append(datum.numpy())\n",
    "                labels.append(label)\n",
    "                class_tot[label] += 1\n",
    "                tot += 1\n",
    "                # if tot >= 10 * class_num:\n",
    "                #     break\n",
    "        except:\n",
    "            print(label)\n",
    "    return TensorDataset(torch.FloatTensor(np.array(data)), torch.LongTensor(np.array(labels)))\n",
    "\n",
    "def MahjongUnlabel():\n",
    "    raw_dataset =  datasets.ImageFolder('../dataset/unlabel', \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((28, 28)),\n",
    "                       transforms.Grayscale(num_output_channels=1),\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "    print(raw_dataset)\n",
    "    return raw_dataset\n",
    "def MahjongTest():\n",
    "    return datasets.ImageFolder('./data2/test', \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((28, 28)),\n",
    "                       transforms.Grayscale(num_output_channels=1),\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad90c913-5e21-4d51-a599-39048311f786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pdb\n",
    "def log_sum_exp(x, axis = 1):\n",
    "    m = torch.max(x, dim = 1)[0]\n",
    "    return m + torch.log(torch.sum(torch.exp(x - m.unsqueeze(1)), dim = axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "875a4dfc-2c83-45f9-bc9c-b3799246f002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1050\n",
      "    Root location: ../dataset/unlabel\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from __future__ import print_function \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import sys\n",
    "import argparse\n",
    "import pdb\n",
    "from torch.utils.tensorboard import *\n",
    "import os\n",
    "\n",
    "import random  \n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# 设置随机种子,保证模型可以复现\n",
    "def seed_everything(seed):\n",
    "    torch.backends.cudnn.deterministic = True  # 将cuda加速的随机数生成器设为确定性模式\n",
    "    torch.backends.cudnn.benchmark = True  # 关闭CuDNN框架的自动寻找最优卷积算法的功能，以避免不同的算法对结果产生影响\n",
    "    torch.manual_seed(seed)  # pytorch的随机种子\n",
    "    np.random.seed(seed)  # numpy的随机种子\n",
    "    random.seed(seed)  # python内置的随机种子\n",
    "\n",
    "\n",
    "seed_everything(2024)\n",
    "class ImprovedGAN(object):\n",
    "    def __init__(self, G, D, labeled, unlabeled, test, args):\n",
    "        # if os.path.exists(args.savedir):\n",
    "        #     print('Loading model from ' + args.savedir)\n",
    "        #     self.G = torch.load(os.path.join(args.savedir, 'G.pkl'))\n",
    "        #     self.D = torch.load(os.path.join(args.savedir, 'D.pkl'))\n",
    "        # else:\n",
    "        #     os.makedirs(args.savedir)\n",
    "        #     self.G = G\n",
    "        #     self.D = D\n",
    "        #     torch.save(self.G, os.path.join(args.savedir, 'G.pkl'))\n",
    "        #     torch.save(self.D, os.path.join(args.savedir, 'D.pkl'))\n",
    "        self.G = G\n",
    "        self.D = D\n",
    "        self.writer = SummaryWriter(log_dir=args.logdir)\n",
    "        if args.cuda:\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "        self.labeled = labeled\n",
    "        self.unlabeled = unlabeled\n",
    "        self.test = test\n",
    "        self.Doptim = optim.Adam(self.D.parameters(), lr=args.lr, betas= (args.momentum, 0.999))\n",
    "        self.Goptim = optim.Adam(self.G.parameters(), lr=args.lr, betas = (args.momentum,0.999))\n",
    "        self.args = args\n",
    "    def trainD(self, x_label, y, x_unlabel):\n",
    "        x_label, x_unlabel, y = Variable(x_label), Variable(x_unlabel), Variable(y, requires_grad = False)\n",
    "        # print(x_label.shape)\n",
    "        # print(x_unlabel.shape)\n",
    "        if self.args.cuda:\n",
    "            x_label, x_unlabel, y = x_label.cuda(), x_unlabel.cuda(), y.cuda()\n",
    "        output_label = self.D(x_label, cuda=self.args.cuda)\n",
    "        output_unlabel = self.D(x_unlabel, cuda=self.args.cuda)\n",
    "        output_fake = self.D(self.G(x_unlabel.size()[0], cuda = self.args.cuda).view(x_unlabel.size()).detach(), cuda=self.args.cuda)\n",
    "        prob_label = torch.gather(output_label, 1, y.unsqueeze(1)) # log e^x_label = x_label \n",
    "        logz_label, logz_unlabel, logz_fake = log_sum_exp(output_label), log_sum_exp(output_unlabel), log_sum_exp(output_fake)\n",
    "        loss_supervised = -torch.mean(prob_label) + torch.mean(logz_label)\n",
    "        loss_unsupervised = 0.5 * (-torch.mean(logz_unlabel) + torch.mean(F.softplus(logz_unlabel))  + # real_data: log Z/(1+Z)\n",
    "                            torch.mean(F.softplus(logz_fake)) ) # fake_data: log 1/(1+Z)\n",
    "        loss = loss_supervised + self.args.unlabel_weight * loss_unsupervised\n",
    "        # print(output_label.max(1)[1])\n",
    "        # print(y)\n",
    "        acc = torch.mean((output_label.max(1)[1] == y).float())\n",
    "        self.Doptim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.Doptim.step()\n",
    "        return loss_supervised.data.cpu().numpy(), loss_unsupervised.data.cpu().numpy(), acc\n",
    "    \n",
    "    def trainG(self, x_unlabel):\n",
    "        fake = self.G(x_unlabel.size()[0], cuda = self.args.cuda).view(x_unlabel.size())\n",
    "        mom_gen, output_fake = self.D(fake, feature=True, cuda=self.args.cuda)\n",
    "        mom_unlabel, _ = self.D(Variable(x_unlabel), feature=True, cuda=self.args.cuda)\n",
    "        mom_gen = torch.mean(mom_gen, dim = 0)\n",
    "        mom_unlabel = torch.mean(mom_unlabel, dim = 0)\n",
    "        loss_fm = torch.mean((mom_gen - mom_unlabel) ** 2)\n",
    "        loss = loss_fm \n",
    "        self.Goptim.zero_grad()\n",
    "        self.Doptim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.Goptim.step()\n",
    "        return loss.data.cpu().numpy()\n",
    "\n",
    "    def train(self):\n",
    "        #assert self.unlabeled.__len__() > self.labeled.__len__()\n",
    "        print(len(self.unlabeled))\n",
    "        print(len(self.labeled))\n",
    "        assert type(self.labeled) == TensorDataset\n",
    "        times = int(np.ceil(self.unlabeled.__len__() * 1. / self.labeled.__len__()))\n",
    "        t1 = self.labeled.tensors[0].clone()\n",
    "        t2 = self.labeled.tensors[1].clone()\n",
    "        print(times)\n",
    "        print(t1.repeat(times,1,1,1).shape)\n",
    "        print(t2.repeat(times).shape)\n",
    "        tile_labeled = TensorDataset(t1.repeat(times,1,1,1),t2.repeat(times))\n",
    "        gn = 0\n",
    "        for epoch in range(self.args.epochs):\n",
    "            self.G.train()\n",
    "            self.D.train()\n",
    "            unlabel_loader1 = DataLoader(self.unlabeled, batch_size = self.args.batch_size, shuffle=True, drop_last=True, num_workers = 4)\n",
    "            unlabel_loader2 = DataLoader(self.unlabeled, batch_size = self.args.batch_size, shuffle=True, drop_last=True, num_workers = 4).__iter__()\n",
    "            label_loader = DataLoader(tile_labeled, batch_size = self.args.batch_size, shuffle=True, drop_last=True, num_workers = 4).__iter__()\n",
    "            loss_supervised = loss_unsupervised = loss_gen = accuracy = 0.\n",
    "            batch_num = 0\n",
    "            # for d in unlabel_loader1:\n",
    "            #     print(d)\n",
    "            #     print('*'*8)\n",
    "            #     break\n",
    "            for (unlabel1, _label1) in unlabel_loader1:\n",
    "                batch_num += 1\n",
    "                unlabel2, _label2 = next(unlabel_loader2)\n",
    "                x, y = next(label_loader)\n",
    "                if args.cuda:\n",
    "                    x, y, unlabel1, unlabel2 = x.cuda(), y.cuda(), unlabel1.cuda(), unlabel2.cuda()\n",
    "                ll, lu, acc = self.trainD(x, y, unlabel1)\n",
    "                loss_supervised += ll\n",
    "                loss_unsupervised += lu\n",
    "                accuracy += acc\n",
    "                lg = self.trainG(unlabel2)\n",
    "                if epoch > 1 and lg > 1:\n",
    "                    lg = self.trainG(unlabel2)\n",
    "                loss_gen += lg\n",
    "                if (batch_num + 1) % self.args.log_interval == 0:\n",
    "                    print('Training: %d / %d' % (batch_num + 1, len(unlabel_loader1)))\n",
    "                    self.writer.add_scalars('loss', {'loss_supervised':ll, 'loss_unsupervised':lu, 'loss_gen':lg}, gn)\n",
    "                    gn += 1\n",
    "                    with torch.no_grad():\n",
    "                        \n",
    "                        self.writer.add_histogram('real_feature', self.D(Variable(x), cuda=self.args.cuda, feature = True)[0], gn)\n",
    "                        self.writer.add_histogram('fake_feature', self.D(self.G(self.args.batch_size, cuda = self.args.cuda), cuda=self.args.cuda, feature = True)[0], gn)\n",
    "                        #self.writer.add_histogram('fc3_bias', self.G.fc3.bias, gn)\n",
    "                        # self.writer.add_histogram('D_feature_weight', self.D.layers[-1].weight, gn)\n",
    "                    self.D.train()\n",
    "                    self.G.train()\n",
    "            loss_supervised /= batch_num\n",
    "            loss_unsupervised /= batch_num\n",
    "            loss_gen /= batch_num\n",
    "            accuracy /= batch_num\n",
    "            print(\"Iteration %d, loss_supervised = %.4f, loss_unsupervised = %.4f, loss_gen = %.4f train acc = %.4f\" % (epoch, loss_supervised, loss_unsupervised, loss_gen, accuracy))\n",
    "            sys.stdout.flush()\n",
    "            if (epoch + 1) % self.args.eval_interval == 0:\n",
    "                print(\"Eval: correct %d / %d\"  % (self.eval(), self.test.__len__()))\n",
    "                print(self.eval()/ self.test.__len__())\n",
    "                # torch.save(self.G, os.path.join(args.savedir, 'G.pkl'))\n",
    "                # torch.save(self.D, os.path.join(args.savedir, 'D.pkl'))\n",
    "                \n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            ret = torch.max(self.D(Variable(x), cuda=self.args.cuda), 1)[1].data\n",
    "        return ret\n",
    "\n",
    "    def eval(self):\n",
    "        self.G.eval()\n",
    "        self.D.eval()\n",
    "        d, l = [], []\n",
    "        for (datum, label) in self.test:\n",
    "            d.append(datum)\n",
    "            l.append(label)\n",
    "        x, y = torch.stack(d), torch.LongTensor(l)\n",
    "        if self.args.cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        pred = self.predict(x)\n",
    "        return torch.sum(pred == y)\n",
    "    def draw(self, batch_size):\n",
    "        self.G.eval()\n",
    "        return self.G(batch_size, cuda=self.args.cuda)\n",
    "        # Existing code...\n",
    "\n",
    "    def save_model(self, save_dir):\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        torch.save(self.G.state_dict(), os.path.join(save_dir, 'G.pth'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(save_dir, 'D.pth'))\n",
    "        print(\"Model saved successfully.\")\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Improved GAN')\n",
    "    parser.add_argument('--batch-size', type=int, default=100, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--epochs', type=int, default=50, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.0005, metavar='LR',\n",
    "                        help='learning rate (default: 0.001)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                        help='CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--eval-interval', type=int, default=1, metavar='N',\n",
    "                        help='how many epochs to wait before evaling training status')\n",
    "    parser.add_argument('--unlabel-weight', type=float, default=0.8, metavar='N',\n",
    "                        help='scale factor between labeled and unlabeled data')\n",
    "    parser.add_argument('--logdir', type=str, default='./logfile', metavar='LOG_PATH', help='logfile path, tensorboard format')\n",
    "    parser.add_argument('--savedir', type=str, default='./models', metavar='SAVE_PATH', help = 'saving path, pickle format')\n",
    "    args = parser.parse_args(args = [])\n",
    "    args.cuda = args.cuda and torch.cuda.is_available()\n",
    "    np.random.seed(args.seed)\n",
    "    gan = ImprovedGAN(Generator(100), Discriminator(), MahjongLabel(42), MahjongUnlabel(), MahjongTest(), args)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e7a7f44-b938-4a82-9818-8c140e1d1254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n",
      "493\n",
      "3\n",
      "torch.Size([1479, 1, 28, 28])\n",
      "torch.Size([1479])\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 0, loss_supervised = 3.8470, loss_unsupervised = 1.9653, loss_gen = 0.0059 train acc = 0.0390\n",
      "Eval: correct 6 / 124\n",
      "tensor(0.0484)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 1, loss_supervised = 3.5894, loss_unsupervised = 1.9407, loss_gen = 0.0107 train acc = 0.0920\n",
      "Eval: correct 24 / 124\n",
      "tensor(0.1935)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 2, loss_supervised = 3.2609, loss_unsupervised = 1.8923, loss_gen = 0.0193 train acc = 0.1560\n",
      "Eval: correct 29 / 124\n",
      "tensor(0.2339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 3, loss_supervised = 2.7684, loss_unsupervised = 1.8196, loss_gen = 0.0351 train acc = 0.2830\n",
      "Eval: correct 46 / 124\n",
      "tensor(0.3710)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 4, loss_supervised = 2.1692, loss_unsupervised = 1.7065, loss_gen = 0.0607 train acc = 0.4770\n",
      "Eval: correct 63 / 124\n",
      "tensor(0.5081)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 5, loss_supervised = 1.7016, loss_unsupervised = 1.5769, loss_gen = 0.0798 train acc = 0.6050\n",
      "Eval: correct 63 / 124\n",
      "tensor(0.5081)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 6, loss_supervised = 1.3693, loss_unsupervised = 1.4196, loss_gen = 0.0863 train acc = 0.6960\n",
      "Eval: correct 72 / 124\n",
      "tensor(0.5806)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 7, loss_supervised = 1.0932, loss_unsupervised = 1.2331, loss_gen = 0.1099 train acc = 0.7560\n",
      "Eval: correct 78 / 124\n",
      "tensor(0.6290)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 8, loss_supervised = 0.9112, loss_unsupervised = 1.0619, loss_gen = 0.1001 train acc = 0.8180\n",
      "Eval: correct 83 / 124\n",
      "tensor(0.6694)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 9, loss_supervised = 0.7674, loss_unsupervised = 0.9205, loss_gen = 0.1279 train acc = 0.8610\n",
      "Eval: correct 84 / 124\n",
      "tensor(0.6774)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 10, loss_supervised = 0.6510, loss_unsupervised = 0.8193, loss_gen = 0.1834 train acc = 0.8810\n",
      "Eval: correct 79 / 124\n",
      "tensor(0.6371)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 11, loss_supervised = 0.5631, loss_unsupervised = 0.7613, loss_gen = 0.1928 train acc = 0.9040\n",
      "Eval: correct 82 / 124\n",
      "tensor(0.6613)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 12, loss_supervised = 0.4658, loss_unsupervised = 0.6813, loss_gen = 0.3817 train acc = 0.9250\n",
      "Eval: correct 82 / 124\n",
      "tensor(0.6613)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 13, loss_supervised = 0.4351, loss_unsupervised = 0.6473, loss_gen = 0.2789 train acc = 0.9230\n",
      "Eval: correct 81 / 124\n",
      "tensor(0.6532)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 14, loss_supervised = 0.3463, loss_unsupervised = 0.6194, loss_gen = 0.2954 train acc = 0.9470\n",
      "Eval: correct 81 / 124\n",
      "tensor(0.6532)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 15, loss_supervised = 0.3225, loss_unsupervised = 0.5971, loss_gen = 0.4649 train acc = 0.9560\n",
      "Eval: correct 87 / 124\n",
      "tensor(0.7016)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 16, loss_supervised = 0.2755, loss_unsupervised = 0.5349, loss_gen = 0.4651 train acc = 0.9720\n",
      "Eval: correct 85 / 124\n",
      "tensor(0.6855)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 17, loss_supervised = 0.2660, loss_unsupervised = 0.5038, loss_gen = 0.4375 train acc = 0.9610\n",
      "Eval: correct 87 / 124\n",
      "tensor(0.7016)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 18, loss_supervised = 0.2221, loss_unsupervised = 0.4724, loss_gen = 0.3875 train acc = 0.9800\n",
      "Eval: correct 83 / 124\n",
      "tensor(0.6694)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 19, loss_supervised = 0.1819, loss_unsupervised = 0.4556, loss_gen = 0.4270 train acc = 0.9830\n",
      "Eval: correct 83 / 124\n",
      "tensor(0.6694)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 20, loss_supervised = 0.1809, loss_unsupervised = 0.4759, loss_gen = 0.5085 train acc = 0.9840\n",
      "Eval: correct 83 / 124\n",
      "tensor(0.6694)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 21, loss_supervised = 0.1719, loss_unsupervised = 0.4318, loss_gen = 0.5510 train acc = 0.9810\n",
      "Eval: correct 85 / 124\n",
      "tensor(0.6855)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 22, loss_supervised = 0.1417, loss_unsupervised = 0.4135, loss_gen = 0.5468 train acc = 0.9910\n",
      "Eval: correct 82 / 124\n",
      "tensor(0.6613)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 23, loss_supervised = 0.1288, loss_unsupervised = 0.3973, loss_gen = 0.5939 train acc = 0.9930\n",
      "Eval: correct 85 / 124\n",
      "tensor(0.6855)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 24, loss_supervised = 0.1244, loss_unsupervised = 0.3680, loss_gen = 0.6530 train acc = 0.9930\n",
      "Eval: correct 87 / 124\n",
      "tensor(0.7016)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 25, loss_supervised = 0.1153, loss_unsupervised = 0.3703, loss_gen = 0.7111 train acc = 0.9930\n",
      "Eval: correct 88 / 124\n",
      "tensor(0.7097)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 26, loss_supervised = 0.1233, loss_unsupervised = 0.3416, loss_gen = 0.7014 train acc = 0.9930\n",
      "Eval: correct 89 / 124\n",
      "tensor(0.7177)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 27, loss_supervised = 0.1007, loss_unsupervised = 0.3578, loss_gen = 0.7569 train acc = 0.9970\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 28, loss_supervised = 0.0960, loss_unsupervised = 0.3348, loss_gen = 0.7736 train acc = 0.9960\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 29, loss_supervised = 0.0887, loss_unsupervised = 0.3012, loss_gen = 0.8117 train acc = 0.9970\n",
      "Eval: correct 90 / 124\n",
      "tensor(0.7258)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 30, loss_supervised = 0.0831, loss_unsupervised = 0.2993, loss_gen = 0.7993 train acc = 0.9960\n",
      "Eval: correct 90 / 124\n",
      "tensor(0.7258)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 31, loss_supervised = 0.0788, loss_unsupervised = 0.2561, loss_gen = 0.8752 train acc = 0.9980\n",
      "Eval: correct 92 / 124\n",
      "tensor(0.7419)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 32, loss_supervised = 0.0728, loss_unsupervised = 0.2390, loss_gen = 0.8552 train acc = 0.9970\n",
      "Eval: correct 92 / 124\n",
      "tensor(0.7419)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 33, loss_supervised = 0.0680, loss_unsupervised = 0.2195, loss_gen = 0.8937 train acc = 0.9990\n",
      "Eval: correct 92 / 124\n",
      "tensor(0.7419)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 34, loss_supervised = 0.0638, loss_unsupervised = 0.2022, loss_gen = 0.9571 train acc = 1.0000\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 35, loss_supervised = 0.0586, loss_unsupervised = 0.1843, loss_gen = 1.0326 train acc = 1.0000\n",
      "Eval: correct 92 / 124\n",
      "tensor(0.7419)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 36, loss_supervised = 0.0551, loss_unsupervised = 0.1638, loss_gen = 1.0882 train acc = 0.9980\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 37, loss_supervised = 0.0480, loss_unsupervised = 0.1465, loss_gen = 1.1303 train acc = 1.0000\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 38, loss_supervised = 0.0535, loss_unsupervised = 0.1420, loss_gen = 1.1826 train acc = 1.0000\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 39, loss_supervised = 0.0506, loss_unsupervised = 0.1297, loss_gen = 1.1486 train acc = 0.9970\n",
      "Eval: correct 89 / 124\n",
      "tensor(0.7177)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 40, loss_supervised = 0.0459, loss_unsupervised = 0.1169, loss_gen = 1.3504 train acc = 1.0000\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 41, loss_supervised = 0.0411, loss_unsupervised = 0.0995, loss_gen = 1.3093 train acc = 1.0000\n",
      "Eval: correct 92 / 124\n",
      "tensor(0.7419)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 42, loss_supervised = 0.0420, loss_unsupervised = 0.0944, loss_gen = 1.3022 train acc = 0.9990\n",
      "Eval: correct 92 / 124\n",
      "tensor(0.7419)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 43, loss_supervised = 0.0368, loss_unsupervised = 0.0878, loss_gen = 1.3609 train acc = 1.0000\n",
      "Eval: correct 92 / 124\n",
      "tensor(0.7419)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 44, loss_supervised = 0.0376, loss_unsupervised = 0.0862, loss_gen = 1.3713 train acc = 0.9990\n",
      "Eval: correct 91 / 124\n",
      "tensor(0.7339)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 45, loss_supervised = 0.0355, loss_unsupervised = 0.0784, loss_gen = 1.1979 train acc = 1.0000\n",
      "Eval: correct 90 / 124\n",
      "tensor(0.7258)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 46, loss_supervised = 0.0315, loss_unsupervised = 0.0829, loss_gen = 1.0111 train acc = 0.9980\n",
      "Eval: correct 90 / 124\n",
      "tensor(0.7258)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 47, loss_supervised = 0.0295, loss_unsupervised = 0.0964, loss_gen = 0.7587 train acc = 0.9990\n",
      "Eval: correct 89 / 124\n",
      "tensor(0.7177)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 48, loss_supervised = 0.0262, loss_unsupervised = 0.0888, loss_gen = 0.7480 train acc = 1.0000\n",
      "Eval: correct 88 / 124\n",
      "tensor(0.7097)\n",
      "Training: 2 / 10\n",
      "Training: 3 / 10\n",
      "Training: 4 / 10\n",
      "Training: 5 / 10\n",
      "Training: 6 / 10\n",
      "Training: 7 / 10\n",
      "Training: 8 / 10\n",
      "Training: 9 / 10\n",
      "Training: 10 / 10\n",
      "Training: 11 / 10\n",
      "Iteration 49, loss_supervised = 0.0292, loss_unsupervised = 0.0866, loss_gen = 0.5171 train acc = 0.9990\n",
      "Eval: correct 87 / 124\n",
      "tensor(0.7016)\n"
     ]
    }
   ],
   "source": [
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "628f2a17-cca8-4d69-a5b3-b2dd06a1ddf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "    # Save the model after trainingc\n",
    "    save_dir = './saved_models'\n",
    "    gan.save_model(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d047b3-0b04-448d-8bb1-7900c6e85caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.15.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148cccfe-f633-45a4-82df-f19783151b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
